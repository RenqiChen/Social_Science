<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation">

  <meta name="keywords" content="Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation">

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation</title>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">


  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/interactive_figures.css">
  
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->

  <script src="https://kit.fontawesome.com/e8d9e5563c.js" crossorigin="anonymous"></script>

  <script>
    document.addEventListener("DOMContentLoaded", function(event) { 
        //do work
      
      const copyButtonLabel = "Copy BibTex";

      // use a class selector if available
      let blocks = document.querySelectorAll("pre");
      console.log(blocks)
      
      blocks.forEach((block) => {
        // only add button if browser supports Clipboard API
        if (navigator.clipboard) {
          let button = document.createElement("button");
      
          button.innerText = copyButtonLabel;
          button.classList.add("btn");
          button.classList.add("btn-primary");
          button.style.alignContent = "center";
          button.style.textAlign = "center";
          block.parentElement.appendChild(button);
      
          button.addEventListener("click", async () => {
            await copyCode(block, button);
          });
        }
      });
      
      async function copyCode(block, button) {
        let code = block.querySelector("code");
        let text = code.innerText;
      
        await navigator.clipboard.writeText(text);
      
        // visual feedback that task is completed
        button.innerText = "BibTex Copied!";
      
        setTimeout(() => {
          button.innerText = copyButtonLabel;
        }, 1000);
      }
  });
  </script>

  <style>

    pre[class*="language-"] {
      position: relative;
      overflow: auto;
    
      /* make space  */
      margin: 5px 0;
      padding: 1.75rem 0 1.75rem 1rem;
      border-radius: 10px;
    }
    
    pre[class*="language-"] button {
      position: absolute;
      top: 5px;
      right: 5px;
    
      font-size: 0.9rem;
      padding: 0.15rem;
     
    
      border: ridge 1px;
      border-radius: 5px;
      text-shadow: #c4c4c4 0 0 2px;
    }
    
    pre[class*="language-"] button:hover {
      cursor: pointer;  
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <span class="author-block">
                <a href="">Haoyang Su</a><sup>1#</sup>,</span>
              <span class="author-block">
                <a href="">Renqi Chen</a><sup>1#</sup>,</span>
              <span class="author-block">
                <a href="">Shixiang Tang</a><sup>1‚Äª</sup>,
              </span>
              <span class="author-block">
                <a href="">Xinzhe Zheng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Jingzhe Li</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Zhenfei Yin</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Wanli Ouyang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Nanqing Dong</a><sup>1‚Äª</sup>,
            </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Artificial Intelligence Laboratory,</span>
<!--             <span class="author-block"><sup>2</sup>Yazhouwan National Laboratory,</span>
            <span class="author-block"><sup>3</sup>China Agricultural University,</span>
            <span class="author-block"><sup>4</sup>Hangzhou Dianzi University,</span>
            <span class="author-block"><sup>5</sup>Fudan university,</span>
            <span class="author-block"><sup>6</sup>Shanghai Jiaotong University</span> -->
            <span class="eql-cntrb"><small><br><sup>#</sup>Co-first Authors</small></span>
            <span class="eql-cntrb"><small><br><sup>‚Äª</sup>Corresponding Authors</small></span>
          </div>
          

   


              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Paper Link. -->
                  <span class="link-block">
                    <a href=" " 
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv (Comming Soon)</span>
                    </a>
                  </span>
                  
                  
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/RenqiChen/The_Crop"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                      </a>
                  </span>
                  <figure>
                    <br>
                    <img src="static/images/example.png" alt="fail" width="100%"">
                    <figcaption class="content has-text-left"  style="word-break:normal"><b>Figure 1. The proposed LLM-based multi-agent system, VirSci, </b>
                      consists of five key steps: Collaborator Selection, where a research team is assembled; Topic Discussion, 
                      where the research topic is determined; Idea Generation, where team members propose and refine ideas; Novelty Assessment,
                      where ideas are evaluated and voted on to select the best one; and Abstract Generation,
                      where the selected idea is developed into a complete abstract.</figcaption>
                  </figure>
            </div>
          </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">‚≠ê Highlights</h2>
        <div class="content has-text-justified">
          <p>
            <ul>
              <li>To the best of our knowledge, we propose the ffrst multi-agent system for conducting scientiffc collaborations in an end-to-end pipeline from team organization to novel scientiffc idea generation. Furthermore, the real data is utilized for role-play and the objective evaluation of ffnal outputs.</li>
              <li>We conduct extensive evaluations to investigate VIRSCI in terms of the team settings and the novelty of generated scientiffc ideas. The results demonstrate that multi-agent collaboration can improve the quality of the outcomes, surpassing the SOTA single-agent method.</li>
              <li>The simulation results align with the important ffndings in Science of Science, such as fresh teams tend to create more innovative research, showcasing the potential of VIRSCI as a powerful tool for future research in this ffeld.</li>
            </ul>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üëÄ Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid advancement of scientific progress requires innovative tools that can accelerate discovery. 
            While recent AI methods, particularly large language models (LLMs), 
            have shown promise in tasks such as hypothesis generation and experimental design, 
            they fall short in replicating the collaborative nature of real-world scientific practices, 
            where diverse teams of experts work together to tackle complex problems. To address the limitation, 
            we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci), designed to mimic the teamwork inherent in scientific research. 
            VirSci organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. 
            Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel and impactful scientific ideas, 
            showing potential in aligning with key insights in the Science of Science field. Our findings suggest that integrating collaborative agents can lead to more innovative scientific outputs, 
            offering a robust system for autonomous scientific discovery.
           
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="dataset-browser">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <div class="column">
          <div class="content" style="text-align:center;">
            <h2 class="title is-3 has-text-centered">üìö Crop Dataset</h2>
            <figure>
              <br>
              <img src="static/images/dataset_pre_distribution.png" alt="fail" width="100%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Figure 2. Hierarchical view of tasks in CROP dataset.</b>
           Dialogues can be single-turn or multi-turn
(first tier). The second tier specifies task types. The third tier further decomposes these types into
finer-grained tasks. Task-specified topics are rendered around the taxonomy.</figcaption>
            </figure>
            <figure>
              <br>
              <img src="static/images/single_turn_table.png" alt="fail" width="100%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Table 1. Composition of single-turn dialogue dataset.</b>
            Please note that despite our data-cleaning efforts,
the final CROP dataset inevitably contain a small amount of data (<0.5%) from other grains like
wheat. As this portion does not dominantly influence the fine-tuning results, it is included into the
final CROP dataset. We have listed it explicitly in the table to avoid any misleading counts.</figcaption>
            </figure>            
            <figure>
              <br>
              <img src="static/images/multi_turn_table.png" alt="fail" width="100%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Table 2. Composition of multi-turn dialogue dataset.</b>
            <p style="color: rgb(129, 190, 206); display: inline;">Blue</p> denotes 3-turn dialogue, <p style="color: rgb(174, 198, 112); display: inline;">green</p> denotes 4-turn dialogue, and <p style="color: rgb(245, 187, 44); display: inline;">yellow</p> denotes 5-turn dialogue.</figcaption>
            </figure>
        </div>

      </div>
    </div>
</section>

      
<section class="section" id="benchmark-browser">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <div class="column">
          <div class="content" style="text-align:center;">
            <h2 class="title is-3 has-text-centered">üìà Crop Benchmark</h2>
            <figure>
              <br>
              <img src="static/images/benchmark_aft_distribution.png" alt="fail" width="80%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Figure 3. Content distribution of benchmark.</b>
           We list the keywords in the produced benchmark for a
deeper insight. Darker colors indicate a higher frequency of occurrence, while lighter colors indicate
a lower frequency of occurrence.</figcaption>
            </figure>
            <figure>
              <br>
              <img src="static/images/benchmark_table.png" alt="fail" width="50%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Table 3. Statistics of the benchmark.</b></figcaption>
            </figure>
            <figure>
              <br>
              <img src="static/images/benchmark_comparison.png" alt="fail" width="100%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Table 4. Benchmark Comparison.</b> CROP benchmark surpasses existing datasets in terms of quantity and locality.<br>
              <sup>1</sup> https://www.certifiedcropadviser.org/become-certified/certifications/.<br>
              <sup>2</sup> https://mais500p500r.sct.embrapa.br/view/index.php. For EMBRAPA, we count the number of test-based inquires related to rice and corn.<br>
              <sup>3</sup> https://www.agriexam.com/agriculture-previous-year-question-paper.</figcaption>
            </figure>
        </div>
      </div>
    </div>
</section>

<section class="section" id="experiments-browser">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <div class="column">
          <div class="content" style="text-align:center;">
            <h2 class="title is-3 has-text-centered">üì¶ Experiments</h2>
            <figure>
              <br>
              <img src="static/images/experiments.png" alt="fail" width="100%"">
              <figcaption class="content has-text-left" style="font-style: normal; word-break:normal"><b>Table 5. Performance of selected LLMs on the CROP benchmark.</b>
              Open-source LLMs are tuned on the CROP dataset in 4 epochs. We indicate the accuracy changes of the fine-tuned LLMs compared
            to the original in <p style="color: rgb(0, 0, 255); display: inline;">blue</p>, where the accuracy has generally improved across various difficulty levels.<br>
           <sup>1</sup> GPT-4 API is ‚Äúgpt-4-turbo-2024-04-09‚Äù. GPT-3.5 API is ‚Äúgpt-3.5-turbo-0125‚Äù. Claude-3 API is ‚Äúclaude-3-opus-20240229‚Äù. Qwen API is ‚Äúqwen-max‚Äù. <br>
                <sup>2</sup> The accuracy of 0.000 and 1.000 is explained in Paper Section 4.3. </figcaption>
            </figure>
        </div>
      </div>
    </div>
</section>
      
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3  has-text-centered">üìå Citation</h2>
            <div class="language-css">
            <pre style="">
<code>
  
</code></pre>
            
          </div>
        </div>
      </div>
    </div>

  </div>
</section>






<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is based on the <a href="https://nerfies.github.io/">Nerfies website template</a>, which is licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script src="./static/js/interactive_figures.js"></script>
</body>
</html>
